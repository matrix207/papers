---
layout: post
title: "nfs"
description: ""
category: storage 
tags: [file system]
---

### About NFS

NFS is "Network File System".

* linux find NFS version, using command `nfsstat -m` on client machine, 找到字符串"vers=4.0"
  - [对比分析各个NFS版本的特点](http://network.51cto.com/art/201008/216664.htm)

### How to use
* On server:
  - service nfs start|stop
  - set ACL (Access Control Lists) of files and directories.
    + setfacl -m other::--- PATH
    + setfacl -m g:GROUP_NAME:rwx PATH
    + setfacl -m g:GROUP_NAME:--- PATH

* On clinet: mount nfs share disk
  - showmount -e 172.16.130.143
  - mkdir /mnt/nfs
  - mount 172.16.130.143:/share/vdshare001 /mnt/nfs
  - ls /mnt/nfs
  - umount /mnt/nfs

* command operation:  

	[root@Ustor ~]# service nfs start
	Starting RPC svcgssd:                                      [  OK  ]
	Starting NFS services:                                     [  OK  ]
	Starting NFS quotas:                                       [  OK  ]
	Starting NFS mountd:                                       [  OK  ]
	Stopping RPC idmapd:                                       [  OK  ]
	Starting RPC idmapd:                                       [  OK  ]
	Starting NFS daemon:                                       [  OK  ]
	[root@Ustor ~]# service nfs status
	rpc.svcgssd (pid 11647) is running...
	rpc.mountd (pid 11657) is running...
	nfsd (pid 11722 11721 11720 11719 11718 11717 11716 11715) is running...
	rpc.rquotad (pid 11653) is running..
	[root@Ustor ~]# ps aux |grep nfs
	root   11713  0.0  0.0      0     0 ?      S    23:34   0:00 [nfsd4]
	root   11714  0.0  0.0      0     0 ?      S    23:34   0:00 [nfsd4_callbacks]
	root   11715  0.0  0.0      0     0 ?      S    23:34   0:00 [nfsd]
	root   11716  0.0  0.0      0     0 ?      S    23:34   0:00 [nfsd]
	root   11717  0.0  0.0      0     0 ?      S    23:34   0:00 [nfsd]
	root   11718  0.0  0.0      0     0 ?      S    23:34   0:00 [nfsd]
	root   11719  0.0  0.0      0     0 ?      S    23:34   0:00 [nfsd]
	root   11720  0.0  0.0      0     0 ?      S    23:34   0:00 [nfsd]
	root   11721  0.0  0.0      0     0 ?      S    23:34   0:00 [nfsd]
	root   11722  0.0  0.0      0     0 ?      S    23:34   0:00 [nfsd]
	root   11904  0.0  0.0 103240   844 pts/1  S+   23:35   0:00 grep nfs
	[root@Ustor ~]# netstat -apn |grep 2049
	tcp     0      0 0.0.0.0:2049         0.0.0.0:*            LISTEN      -                   
	tcp     0      0 :::2049              :::*                 LISTEN      -                   
	udp     0      0 0.0.0.0:2049         0.0.0.0:*                        -                   
	udp     0      0 :::2049              :::*                             - 
	[root@Ustor ~]# service nfs stop
	Shutting down NFS daemon:                                  [  OK  ]
	Shutting down NFS mountd:                                  [  OK  ]
	Shutting down NFS quotas:                                  [  OK  ]
	Shutting down RPC svcgssd:                                 [  OK  ]

* check status from /proc/fs/nfs and /proc/fs/nfsd/

### Optimal
* ★★★ **[nfs的传输速度优化](http://blog.csdn.net/yangzhongxuan/article/details/7918884)**
  - 设置块大小 
    + time dd if=/dev/zero of=/testfs/testfile bs=8k count=1024 测试nfs写
    + time dd if=/testfs/testfile of=/dev/null bs=8k 测试nfs读
  - 网络传输包的大小
    + ping -s 2048 -f hostname, try different package size
    + nfsstat －o net
    + tracepath node1/端口号
    + ifconfig eth0
    + ifconfig eth0 mtu 16436, modify MTU value
    + /proc/sys/net/ipv4/ipfrag_high_thresh和/proc/sys/net/ipv4/ipfrag_low_thresh
  - nfs挂载的优化
    + timeo:如果超时，客户端等待的时间，以十分之一秒计算。
    + retrans：超时尝试的次数。
    + bg：后台挂载，很有用
    + hard：如果server端没有响应，那么客户端一直尝试挂载。
    + wsize：写块大小
    + rsize：读块大小
    + intr：可以中断不成功的挂载
    + noatime：不更新文件的inode访问时间，可以提高速度。
    + async：异步读写。
  - nfsd的个数
    + ps -efl |grep nfsd
    + vi /etc/init.d/nfs, modify RPCNFSDCOUNT 
    + service nfs restart
  - nfsd的队列长度
    + /proc/sys/net/core/rmem_default
    + /proc/sys/net/core/rmem_max
    + /proc/sys/net/core/wmem_default
    + /proc/sys/net/core/wmem_max
    + vi /etc/sysctl.conf
  - mount 192.168.1.220:/mnt/nfs /mnt/nfs_t -o nolock, rsize=1024,wsize=1024,timeo=15

* **Linux NFS服务性能优化**
  - nfsstat -rc
  - <http://blog.chinaunix.net/uid-24404943-id-3389539.html>
  - NFS的队列大小, modify server and client machine: (262144 = 256KB)  
    #echo 262144 > /proc/sys/net/core/rmem_default  
    #echo 262144 > /proc/sys/net/core/rmem_max  
    #echo 262144 > /proc/sys/net/core/wmmen_default  
    #echo 262144 > /proc/sys/net/core/wmmen_max  
  - [root@localhost iperf-2.0.5]# dd if=/dev/zero of=/tmp/test01.dat bs=1M count=10240   
    10240+0 records in  
    10240+0 records out  
    10737418240 bytes (11 GB) copied, 28.2585 s, 380 MB/s  
  - ping -s 2048 -f 192.16.110.80
  - <http://www.cnblogs.com/derekchen/archive/2013/01/17/2865207.html>
  - <http://www.lichaozheng.info/2011/10/13/nfs性能优化/>
  - <http://blog.csdn.net/anghlq/article/details/8532312>
  - tracepath 192.16.110.80
  - [root@localhost iperf-2.0.5]# echo "4096" >/sys/class/net/enp10s0f0/mtu
  - [root@localhost iperf-2.0.5]# dd if=/dev/zero of=/tmp/test04.dat bs=1M count=10240  
    10737418240 bytes (11 GB) copied, 28.0778 s, 382 MB/s  


* NFS共享在使用前需要挂载（mount）。挂载时使用的参数很大程度上影响了读写的性能
  - 1. TCP or UDP
  - 2. rsize和wsize，每次读写的最大值
  - 3.  sync和async. sync参数会强制wsize变成4KB，这会大大降低写性能。 

* **关于SAMBA和NFS是否支持断点续传**
  - 经过测试，得出如下结论：
    + 1.samba 不支持
    + 2.nfs     支持
  - 测试环境和步骤如下：
  - 服务端：
    + 1.172.16.130.200， Centos7.0
  - Windows 客户端:
    + 1.yujl本地机器
    + 2.开始->运行->\\172.16.130.200
    + 3.拷贝一个大的iso文件到xuni文件夹
    + 4.去机房拔掉172.16.130.200机器的网线
    + 5.发现本地的拷贝窗口停止传送数据
    + 6.接上网线，拷贝窗口仍然没有继续传送的迹象
  - Linux 客户端:
    + 1.我本地机器
    + 2.挂载172.16.130.200的/share/sambatest目录到本地的/mnt/nfs
    + 3.cp ~/Downloads/iso/CentOS-6.5-x86_64-bin-DVD1.iso /mnt/nfs/
    + 4.去机房拔掉172.16.130.200机器的网线
    + 5.确认本地无法连接172.16.130.200
    + 6.接上网线，使用ls -l /mnt/nfs/发现iso文件的大小还继续增加
    + 7.待cp完成后，md5sume计算两个iso文件，发现md5值一
  - 不支持，<http://bbs.chinaunix.net/thread-4057603-1-1.html>
  - <http://bbs.chinaunix.net/thread-4057603-1-1.html>

### Code analysed(kernel version: linux-2.6.32-279.el6)
* NFS 文件系统主要分为三个部分：The Protocol（网络协议），Client Side（NFS 客户端）和 Server Side（NFS 服务器）
  - NFS 客户端提供了接口，保证用户或者应用程序能像访问本地文件系统一样访问NFS 文件系统，
  - NFS 服务器作为数据源，为 NFS 客户端提供真实的文件系统服务
  - NFS 网络协议则使得 NFS 客户端和 NFS 服务器能够高效和可靠地进行通信
  - NFS 网络协议使用的是 RPC（Remote Procedure Call，远程过程调用）/XDR（External Data Representation，外部数据表示）机制

* code file list: 

	[dennis@localhost fs]$ pwd
	/home/dennis/work/kernel/linux-2.6.32-279.el6/fs
	[dennis@localhost fs]$ ls nfs  
    cache_lib.c      file.c           nfs2xdr.c            nfsroot.c  
    cache_lib.h      fscache.c        nfs3acl.c            pagelist.c  
    callback.c       fscache.h        nfs3proc.c           pnfs.c  
    callback.h       fscache-index.c  nfs3xdr.c            pnfs_dev.c  
    callback_proc.c  getroot.c        nfs4filelayout.c     pnfs.h  
    callback_xdr.c   idmap.c          nfs4filelayoutdev.c  proc.c  
    client.c         inode.c          nfs4filelayout.h     read.c  
    delegation.c     internal.h       nfs4_fs.h            super.c  
    delegation.h     iostat.h         nfs4namespace.c      symlink.c  
    dir.c            Kconfig          nfs4proc.c           sysctl.c  
    direct.c         Makefile         nfs4renewd.c         unlink.c  
    dns_resolve.c    mount_clnt.c     nfs4state.c          write.c  
    dns_resolve.h    namespace.c      nfs4xdr.c  
	[dennis@localhost fs]$ ls nfsd
	auth.c    Makefile    nfs4callback.c  nfscache.c  nfssvc.c  xdr3.h
	auth.h    nfs2acl.c   nfs4idmap.c     nfsctl.c    nfsxdr.c  xdr4.h
	cache.h   nfs3acl.c   nfs4proc.c      nfsd.h      state.h   xdr.h
	export.c  nfs3proc.c  nfs4recover.c   nfsfh.c     stats.c
	Kconfig   nfs3xdr.c   nfs4state.c     nfsfh.h     vfs.c
	lockd.c   nfs4acl.c   nfs4xdr.c       nfsproc.c   vfs.h
	[dennis@localhost fs]$ ls nfs_common
	Makefile  nfsacl.c
	[dennis@localhost fs]$ cd ../include/linux/
	[dennis@localhost linux]$ ls nfs*
	nfs2.h      nfs4.h        nfsd_idmap.h  nfs_fs_sb.h  nfs_iostat.h  nfs_xdr.h
	nfs3.h      nfs4_mount.h  nfs_fs.h      nfs.h        nfs_mount.h
	nfs4_acl.h  nfsacl.h      nfs_fs_i.h    nfs_idmap.h  nfs_page.h

	nfsd:
	const.h  debug.h  export.h  Kbuild  nfsfh.h  stats.h  syscall.h

* Client Side 源代码  

  Client Side 的头文件在 include/linux/ 下面，C 文件在 fs/nfs 下面。

    dir.c/file.c/inode.c/symlink.c/unlink.c：与文件操作相关的系统调用
    read.c/write.c/flushd.c：文件读写
    mount_clnt.c/nfs_root.c：将 NFS 文件系统作为 root 目录的相关实现
    proc.c/nfs2xdr.c/nfs3proc.c/nfs3xdr.c：网络数据交换 

与文件操作相关的系统调用都在 struct file_operations，struct inode_operations   
这两个数据结构里面定义。文件的读操作 nfs_file_read 和写操作 nfs_file_write 被单  
独提出来，因为文件读写性能将直接关系到文件系统的成败

* Server Side 源代码

Server Side 的头文件在 include/linux/nfsd 下面，C 文件在 fs/nfsd 下面。

    auth.c/lockd.c/export.c/nfsctl.c/nfscache.c/nfsfh.c/stats.c：导出目录的访问管理
    nfssvc.c：NFS 服务 deamon 的实现
    vfs.c：将 NFS 文件系统的操作转换成具体文件系统的操作
    nfsproc.c/nfsxdr.c/nfs3proc.c/nfs3xdr.c：网络数据交换

导出目录的访问管理主要解决网络文件系统实现面临的几个重要问题，包括目录导出服务，  
外部访问的权限控制，多客户端以及客户端与服务器的文件并发操作等。 

* process number of nfsd:  

* rename call stack:  

	client: nfs_rename ->  
	server: nfsd4_rename -> nfsd_rename 

* **To be continue...**

### Reference
* **[NFS文件系统源代码剖析](http://www.ibm.com/developerworks/cn/linux/l-cn-nfs/)**
* [NFS读写块大小问题分析](http://zohead.com/archives/nfs-rwsize/)
* [NFS性能优化手册](http://www.lichaozheng.info/2011/10/13/nfs性能优化/)

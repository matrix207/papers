---
layout: post
title: "use raid"
description: ""
category: storage
tags: [storage]
---


### Linux下建立raid1

	1、先用fdisk在硬盘上划分出空间。
		fdisk /dev/sdc  (后面的根据自己实际情况修改，因为我这里是虚拟机，
		所以就用2个500M的来做成一个raid)
		然后将其的功能改为 Linux raid autodetect 
		(也就是在fdisk下面 用t选择功能然后输入 -->fd)

	2、建立raid
		mdadm -C /dev/md1 -l 1 -n 2 /dev/sda /dev/sdb
		下面是在分区上建raid
		mdadm -C /dev/md1 -l 1 -n 2 /dev/sda -n 2 /dev/sda1 /dev/sda2
		mdadm -C raid阵列所在 -l raid等级 -n 设备数 设备分别是什么
		建立完毕之后，可以通过cat /proc/mdstat 查看是否成功

	3、格式化
		mkfs.ext3 /dev/md1

	4、挂载
		mount /dev/md1 /raid1

	5、建立mdadm.conf文件
		echo 'DEVICE /dev/sd[ab]' > /etc/mdadm.conf
		mdadm -Ds >> /etc/mdadm.conf

	6. view raid
		mdadm -D /dev/md1
		cat /proc/mdstat
		mdadm -E /dev/sda
		mdadm -E /dev/sdb
	
	7. 配置mdadm开机自启动 
		设备配置文件只能使系统在开机时正常启用RAID设备，但自动挂载RAID设备还是要再修改/etc/fstab
		#vi /etc/fstab
		===============================================
		/dev/md0 /mnt/raid ext3 defaults 0 0
		===============================================

	8. 停止与开启RAID设备：
		停止：
		#umount /mnt/raid
		#mdadm -S /dev/md0
		mdadm: stopped /dev/md0
		开启：
		使用配置文件时：
		#mdadm -As /dev/md0
		mdadm: /dev/md0 has been started with 3 drives and 1 spare.
		没有使用配置文件时：
		#mdadm -A /dev/md0 /dev/sd[bcde]
		mdadm: /dev/md0 has been started with 3 drives and 1 spare.

	9. 故障演示
		1).将一个磁盘标记为faulty，模拟硬盘坏损
		#mdadm /dev/md0 -f /dev/sdb
		2).查看RAID5重建过程
		#mdadm -D /dev/md0	
		#cat /proc/mdstat 
		3).查看完成坏损设备后的RAID状态
		#mdadm -D /dev/md0
		#cat /proc/mdstat 
		4).移除坏损设备
		#mdadm /dev/md0 -r /dev/sdb
		mdadm: hot removed /dev/sdb
		5).添加新的设备
		#mdadm /dev/md0 -a /dev/sdb
		mdadm: added /dev/sdb
		6).查看最终状态
		#mdadm -D /dev/md0
		#cat /proc/mdstat 

	10. 删除整个RAID：
		mdadm /dev/md0 --fail /dev/sda --remove /dev/sda
		mdadm /dev/md0 --fail /dev/sdb --remove /dev/sdb
		mdadm --stop /dev/md0
		mdadm --misc --zero-superblock /dev/sda
		mdadm --misc --zero-superblock /dev/sdb
		即： 先删除RAID中的所有设备，然后停止该RAID即可

### mdadm语法

	基本语法 ： mdadm [mode] [options]
	[mode] 有7种：
		Assemble：将以前定义的某个阵列加入当前在用阵列。
		Build：   Build a legacy array ，每个device 没有 superblocks
		Create：  创建一个新的阵列，每个device 具有 superblocks
		Manage： 管理阵列，比如 add 或 remove
		Misc：   允许单独对阵列中的某个 device 做操作，比如抹去superblocks 或 终止在用的阵列。
		Follow or Monitor:监控 raid 1,4,5,6 和 multipath 的状态
		Grow：   改变raid 容量或 阵列中的 device 数目
	可用的 [options]:
	-A, --assemble：加入一个以前定义的阵列
	-B, --build：Build a legacy array without superblocks.
	-C, --create：创建一个新的阵列
	-Q, --query：查看一个device，判断它为一个 md device 或是 一个 md 阵列的一部分
	-D, --detail：打印一个或多个 md device 的详细信息
	-E, --examine：打印 device 上的 md superblock 的内容
	-F, --follow, --monitor：选择 Monitor 模式
	-G, --grow：改变在用阵列的大小或形态
	-h, --help：帮助信息，用在以上选项后，则显示该选项信息
	--help-options
	-V, --version
	-v, --verbose：显示细节
	-b, --brief：较少的细节。用于 --detail 和 --examine 选项
	-f, --force
	-c, --config= ：指定配置文件，缺省为 /etc/mdadm/mdadm.conf
	-s, --scan：扫描配置文件或 /proc/mdstat以搜寻丢失的信息。配置文件/etc/mdadm/mdadm.conf
	create 或 build 使用的选项:
	-c, --chunk=:Specify chunk size of kibibytes. 缺省为 64.
	--rounding=: Specify rounding factor for linear array (==chunk size)
	-l, --level=:设定 raid level.
	--create可用:linear, raid0, 0, stripe, raid1,1, mirror, raid4, 4, raid5, 5, raid6, 6, multipath, mp.
	--build可用：linear, raid0, 0, stripe.
	-p, --parity=：设定 raid5 的奇偶校验规则:eft-asymmetric, left-symmetric, right-asymmetric, right-symmetric, la, ra, ls, rs.缺省为left-symmetric
	--layout=:类似于--parity
	-n, --raid-devices=:指定阵列中可用 device 数目，这个数目只能由 --grow 修改
	-x, --spare-devices=：指定初始阵列的富余device 数目
	-z, --size=：组建RAID1/4/5/6后从每个device获取的空间总数
	--assume-clean:目前仅用于 --build 选项
	-R, --run:阵列中的某一部分出现在其他阵列或文件系统中时，mdadm会确认该阵列。此选项将不作确认。
	-f, --force:通常mdadm不允许只用一个device 创建阵列，而且创建raid5时会使用一个device作为missing drive。此选项正相反。
	-a, --auto{=no,yes,md,mdp,part,p}{NN}：

### other:

	1). check file system type
		before check, should mount the device first
		[root@localhost ]# df -T /mnt/raid1/
		Filesystem    Type   1K-blocks      Used Available Use% Mounted on
		/dev/md0      ext3   961433496    204572 912390856   1% /mnt/raid1
		[root@localhost ]# mount
		ubi0 on / type ubifs (rw)
		proc on /proc type proc (rw)
		sysfs on /sys type sysfs (rw)
		devpts on /dev/pts type devpts (rw,gid=5,mode=620)
		none on /var/tmp type tmpfs (rw)
		/dev/md0 on /mnt/raid1 type ext3 (rw)
		[root@localhost ]# df -T
		Filesystem    Type   1K-blocks      Used Available Use% Mounted on
		ubi0         ubifs      201464    191516      9948  96% /
		none         tmpfs       62136         0     62136   0% /var/tmp
		/dev/md0      ext3   961433496    204572 912390856   1% /mnt/raid1

		reference:
		(1). Linux how to determine the file system type
			www.cyberciti.biz/faq/linux-how-to-determine-find-out-file-system-type/ 
	2).如果想了解你的kernel目前支持哪些文件系统，可以查看/proc/filesystems的内容 
		reference:
		(1).linux /etc/fstab 文件说明 www.wokeke.com/?p=350 
			
### Reference:

* [鳥哥的 Linux 私房菜 軟體磁碟陣列 (Software RAID)](http://linux.vbird.org/linux_basic/0420quota.php#raid)
* [Linux建立Raid](http://page.renren.com/600235506/note/486081565?op=pre&curTime=1282876355000)
* [mdadm详解](http://blog.csdn.net/sense5/article/details/3888249)
* [How to determine RAID controller type and a model](http://supportex.net/2010/11/determine-raid-controller-type-model/)
* [Linux: How to delete a partition with fdisk command](www.cyberciti.biz/faq/linux-how-to-delete-a-partition-with-fdisk-command/)
* [Linux DD命令删除掉分区shell](www.51chongdian.net/bbs/thread-35739-1-1.html)
* [使用libparted库写个程序来打印我们的设备信息](blog.csdn.net/fjb2080/article/details/5032274)
* [linux fdisk 分区、格式化、挂载！](yuetao.org/linux-fdisk/)
* [关于删除软raid设备md0](www.ixpub.net/thread-763965-1-1.html)
* [Linux软Raid配置](http://david0341.iteye.com/blog/382399)
* [mdadm使用详解及RAID 5简单分析](http://blog.csdn.net/sense5/article/details/1828868)

### 我的一些raid操作: 

	1. stop raid
		mdadm -S /dev/md0
		mdadm -S /dev/md1
		mdadm -S /dev/md126
		mdadm -S /dev/md127
	2. create raid 1
		mdadm -Cv -l1 -n2 /dev/sda /dev/sdb --assume-clean --home-host=raidtest
	3. check states
		cat /proc/mdstat
		
	系统中原来插有两块盘，分别显示为/dev/sda /dev/sdb
	如果把第一块盘/dev/sda拔掉，重启后，第二块盘自动识别为/dev/sda
	如果原来/dev/sda和/dev/sdb建了raid1，拔掉/dev/sda并重启系统后，做如下操作:
	[root@localhost ]# cat /proc/mdstat 
	Personalities : [linear] [raid0] [raid1] 
	md0 : active raid1 sda[1]
		  976761424 blocks super 1.2 [2/1] [_U]  # 正常应该是[UU]
		  
	unused devices: <none>
	[root@localhost ]# mdadm --detail /dev/md0
	/dev/md0:
			Version : 1.2
	  Creation Time : Fri Mar 29 06:48:49 2013
		 Raid Level : raid1
		 Array Size : 976761424 (931.51 GiB 1000.20 GB)
	  Used Dev Size : 976761424 (931.51 GiB 1000.20 GB)
	   Raid Devices : 2
	  Total Devices : 1
		Persistence : Superblock is persistent

		Update Time : Fri Mar 29 07:17:39 2013
			  State : clean, degraded
	 Active Devices : 1
	Working Devices : 1
	 Failed Devices : 0
	  Spare Devices : 0

			   Name : mytestraid:0
			   UUID : c76eab52:2e80d8e1:67772808:024ea0b6
			 Events : 6

		Number   Major   Minor   RaidDevice State
		   0       0        0        0      removed     # 这里看到有一块盘被移除了
		   1       8        0        1      active sync   /dev/sda
	[root@localhost ]# 


	正常情况
	[root@localhost ]# cat /proc/mdstat 
	Personalities : [linear] [raid0] [raid1] 
	md0 : active raid1 sdb[1] sda[0]
		  976761424 blocks super 1.2 [2/2] [UU]
		  
	unused devices: <none>

	拔掉一块raid盘，删掉剩下的raid盘数据，重启后插入有raid数据的盘
	[root@localhost ]# cat /proc/mdstat 
	Personalities : [linear] [raid0] [raid1] 
	md127 : inactive sdb[0](S)
		  976761560 blocks super 1.2
